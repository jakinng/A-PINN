{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakinng/A-PINN/blob/main/multistage_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBehqVZNLI7B",
        "outputId": "0436f99f-5839-40ad-b31e-3c293c709baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyDOE\n",
            "  Downloading pyDOE-0.3.8.zip (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyDOE) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyDOE) (1.11.4)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-py3-none-any.whl size=18168 sha256=5ce6f5840c0f04df9061d345a01954e89e57af3bd20d4172403e535ac7a38b7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/b6/d7/c6b64746dba6433c593e471e0ac3acf4f36040456d1d160d17\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install pyDOE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dg18aVQx-F6t"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "_1AvKcpPACDH",
        "outputId": "2c4c72a3-75f7-4c56-d640-6ae92aead964"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "#@title Custom Sampling\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import scipy\n",
        "import jax.scipy as jsp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def gaussian1D_smooth(f, sig, wid):\n",
        "    '''\n",
        "    :param f: equally spaced 1D position matrix  (N, 1)\n",
        "    :param sig: stan. devi of gaussian filter (1, ) or scalor\n",
        "    :param wid: wid of the filter matrix (1, ) or scalor integer\n",
        "    '''\n",
        "    wid = jnp.int32(wid)\n",
        "    xg = jnp.linspace(-sig, sig, wid)\n",
        "    window = jsp.stats.norm.pdf(xg)\n",
        "    win_n = window / jnp.sum(window)\n",
        "    f_smooth = scipy.signal.convolve(f[:, 0], win_n, mode='same')[:, None]\n",
        "    return f_smooth\n",
        "\n",
        "\n",
        "# smooth the imaging using Gaussian filter\n",
        "def gaussian2D_smooth(f, sig, wid):\n",
        "    '''\n",
        "    :param f: equally spaced 2D position matrix [N, N]\n",
        "    :param sig: stan. devi of gaussian filter (2, )\n",
        "    :param wid: wid of the filter matrix (2, ) integer\n",
        "    '''\n",
        "    wid = jnp.int32(wid)\n",
        "    xg = jnp.linspace(-sig[0], sig[0], wid[0])\n",
        "    yg = jnp.linspace(-sig[1], sig[1], wid[1])\n",
        "    window = jsp.stats.norm.pdf(xg) * jsp.stats.norm.pdf(yg)[:, None]\n",
        "    win_n = window / jnp.sum(window)\n",
        "    f_smooth = scipy.signal.convolve2d(f, win_n, mode='same')\n",
        "    return f_smooth\n",
        "\n",
        "\n",
        "# sample the data based on a given probability distribution\n",
        "def colloc1D_set(key, x, f, Ns):\n",
        "    '''\n",
        "    :param x: 1-D position array (N, 1)\n",
        "    :param f: 1-D distribution array (N, 1)\n",
        "    :param Ns: number of points to sample\n",
        "    '''\n",
        "    # remove last element in each direction\n",
        "    xc = x[0:-1, :]\n",
        "    fc = f[0:-1, :]\n",
        "    dx = xc[1] - xc[0]\n",
        "    seq = jnp.arange(fc.shape[0] + 1)\n",
        "    # generate key for random variables\n",
        "    keys = jax.random.split(key, num=2)\n",
        "\n",
        "    # obtain the cumulative sum of the z value\n",
        "    b = jnp.hstack([0., jnp.cumsum(fc)])\n",
        "    # obtain the random variable\n",
        "    c = jax.random.uniform(keys[0], [Ns]) * b[-1]\n",
        "    # generate the index position of each collocation point following the distribution\n",
        "    # (using the interpolate the index of grid where each random variable stands)\n",
        "    posi_intp = jnp.interp(c, b, seq)\n",
        "    # round the result to guarantee that the index position is integer\n",
        "    posi = jnp.int32(jnp.floor(posi_intp))\n",
        "    # obtain the real position of each collocation point\n",
        "    px = xc[posi, :]\n",
        "    # generate a random fraction for each collocation point\n",
        "    posi_add = jax.random.uniform(keys[1], [c.shape[0], 1])\n",
        "    # add the random fraction to the position of each collocation points\n",
        "    x_col = px + posi_add * dx\n",
        "\n",
        "    return x_col\n",
        "\n",
        "\n",
        "# sample the data based on a given probability distribution\n",
        "def colloc2D_set(key, X, Y, F, Ns):\n",
        "    '''\n",
        "    :param key: Key for random\n",
        "    :param X: 2-D X position array (N, N)\n",
        "    :param Y: 2-D Y position array (N, N)\n",
        "    :param F: 2-D distribution array (N, N)\n",
        "    :param Ns: number of points to sample\n",
        "    '''\n",
        "\n",
        "    # remove last element in each direction\n",
        "    Xc = X[0:-1, 0:-1]\n",
        "    Yc = Y[0:-1, 0:-1]\n",
        "    Fc = F[0:-1, 0:-1]\n",
        "    f = Fc.flatten()\n",
        "\n",
        "    x = X[0, :]\n",
        "    y = Y[:, 0]\n",
        "    dx = x[1] - x[0]\n",
        "    dy = y[1] - y[0]\n",
        "    seq = jnp.arange(f.shape[0] + 1)\n",
        "    # generate key for random variables\n",
        "    keys = jax.random.split(key, num=2)\n",
        "\n",
        "    # obtain the cumulative sum of the z value\n",
        "    b = jnp.hstack([0., jnp.cumsum(f)])\n",
        "    # obtain the random variable\n",
        "    c = jax.random.uniform(keys[0], [Ns]) * b[-1]\n",
        "\n",
        "    # generate the index position of each collocation point following the distribution\n",
        "    # (using the interpolate the index of grid where each random variable stands)\n",
        "    posi_intp = jnp.interp(c, b, seq)\n",
        "    # round the result to guarantee that the index position is integer\n",
        "    posi_rd = jnp.floor(posi_intp)\n",
        "    # obtain the 2D position of each collocation point in the position matrix\n",
        "    idx_out = jnp.int32(jnp.floor(posi_rd / Fc.shape[1]))\n",
        "    idx_in = jnp.int32(posi_rd % Fc.shape[1])\n",
        "    # obtain the real position of each collocation point\n",
        "    px = Xc[idx_out, idx_in]\n",
        "    py = Yc[idx_out, idx_in]\n",
        "\n",
        "    # generate a random fraction for each collocation point\n",
        "    posi_add = jax.random.uniform(keys[1], [2, c.shape[0]])\n",
        "    # add the random fraction to the position of each collocation points\n",
        "    Px = px + posi_add[0] * dx\n",
        "    Py = py + posi_add[1] * dy\n",
        "\n",
        "    # group the x,y position of the collocation points into one [Nx2] matrix\n",
        "    X_col = jnp.hstack((Px[:, None], Py[:, None]))\n",
        "\n",
        "    return X_col\n",
        "\n",
        "# sample the data based on a given probability distribution\n",
        "def colloc2Dgrid_set(key, X, Y, F, Ns):\n",
        "    '''\n",
        "    :param key: Key for random\n",
        "    :param X: 2-D X position array (N, N)\n",
        "    :param Y: 2-D Y position array (N, N)\n",
        "    :param F: 2-D distribution array (N, N)\n",
        "    :param Ns: number of points to sample\n",
        "    '''\n",
        "\n",
        "    # remove last element in each direction\n",
        "    Xc = X[0:, 0:]\n",
        "    Yc = Y[0:, 0:]\n",
        "    Fc = F[0:, 0:]\n",
        "    f = Fc.flatten()\n",
        "\n",
        "    x = X[0, :]\n",
        "    y = Y[:, 0]\n",
        "    dx = x[1] - x[0]\n",
        "    dy = y[1] - y[0]\n",
        "    seq = jnp.arange(f.shape[0] + 1)\n",
        "    # generate key for random variables\n",
        "    keys = jax.random.split(key, num=2)\n",
        "\n",
        "    # obtain the cumulative sum of the z value\n",
        "    b = jnp.hstack([0., jnp.cumsum(f)])\n",
        "    # obtain the random variable\n",
        "    c = jax.random.uniform(keys[0], [Ns]) * b[-1]\n",
        "\n",
        "    # generate the index position of each collocation point following the distribution\n",
        "    # (using the interpolate the index of grid where each random variable stands)\n",
        "    posi_intp = jnp.interp(c, b, seq)\n",
        "    # round the result to guarantee that the index position is integer\n",
        "    posi_rd = jnp.floor(posi_intp)\n",
        "    # obtain the 2D position of each collocation point in the position matrix\n",
        "    idx_out = jnp.int32(jnp.floor(posi_rd / Fc.shape[1]))\n",
        "    idx_in = jnp.int32(posi_rd % Fc.shape[1])\n",
        "    idx_1d = idx_out * Fc.shape[1] + idx_in\n",
        "    # # obtain the real position of each collocation point\n",
        "    # px = Xc[idx_out, idx_in]\n",
        "    # py = Yc[idx_out, idx_in]\n",
        "    # # group the x,y position of the collocation points into one [Nx2] matrix\n",
        "    # X_col = jnp.hstack((px[:, None], py[:, None]))\n",
        "    # X_col2 = Xc.flatten()[idx_1d]\n",
        "    return idx_1d\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # example for the 1D collocation set\n",
        "    x = jnp.linspace(-1, 1, 101)[:, None]\n",
        "    f = 10 * jnp.exp(-100 * x**2) + 1\n",
        "    f_s = gaussian1D_smooth(f, 1, 5)  # f must be column\n",
        "    Ns = 500\n",
        "\n",
        "    fig = plt.figure(figsize=[10, 4], dpi=100)\n",
        "    ax = plt.subplot(111)\n",
        "    ax.plot(x, f, 'b-', linewidth=0.5)\n",
        "    ax.plot(x, f_s, 'r--', linewidth=0.5)\n",
        "    plt.show()\n",
        "\n",
        "    seed = np.random.choice(1000, 1)\n",
        "    key = jax.random.PRNGKey(seed[0])\n",
        "    x_col = colloc1D_set(key, x, f, Ns)\n",
        "\n",
        "    fig = plt.figure(figsize=[10, 4], dpi=100)\n",
        "    ax = plt.subplot(111)\n",
        "    ax.plot(x_col, jnp.zeros(x_col.shape), 'bx', linewidth=0.5)\n",
        "    ax.plot(x, f, 'r--')\n",
        "    ax.set_ylabel('$x$', fontsize=15, rotation=0)\n",
        "    ax.set_title('Function', fontsize=10)\n",
        "    ax.set_xlim([-1.05, 1.05])\n",
        "    plt.show()\n",
        "\n",
        "    #%% example for the 2D collocation set\n",
        "    x = jnp.linspace(-1, 1, 101)\n",
        "    y = jnp.linspace(-1, 1, 101)\n",
        "    X, Y = jnp.meshgrid(x, y)\n",
        "    F = 10 * jnp.exp(-10 * (X ** 2 + 10*Y ** 2)) + 1\n",
        "    Ns = 5000\n",
        "\n",
        "    seed = np.random.choice(1000, 1)\n",
        "    seed = [509]\n",
        "    key = jax.random.PRNGKey(seed[0])\n",
        "    X_col = colloc2D_set(key, X, Y, F, Ns)\n",
        "\n",
        "    fig2 = plt.figure(figsize=[8, 8], dpi=100)\n",
        "    ax = plt.subplot(111)\n",
        "    ax.plot(X_col[:, 0], X_col[:, 1], 'bx', linewidth=0.5)\n",
        "    ax.set_ylabel('$x$', fontsize=15, rotation=0)\n",
        "    ax.set_title('Function', fontsize=10)\n",
        "    ax.set_xlim([-1.05, 1.05])\n",
        "    plt.show()\n",
        "\n",
        "    #%% obtain the histogram from the sampling data\n",
        "\n",
        "    H = jnp.histogram2d(X_col[:,0], X_col[:, 1], bins=[x.shape[0], y.shape[0]])[0]\n",
        "    H = H.T  # Histogram does not follow Cartesian convention\n",
        "\n",
        "    fig3 = plt.figure(figsize=(7, 7))\n",
        "    ax = fig3.add_subplot(111, title='pcolormesh: actual edges', aspect='equal')\n",
        "    im = ax.pcolormesh(X, Y, H)\n",
        "    fig3.colorbar(im, ax=ax)\n",
        "    plt.show()\n",
        "\n",
        "    #%% smooth the histogram using Gaussion filter\n",
        "\n",
        "    H_sm = gaussian2D_smooth(H, [1, 1], [5, 5])\n",
        "    fig4 = plt.figure(figsize=(7, 7))\n",
        "    ax = fig4.add_subplot(111, aspect='equal')\n",
        "    im2 = ax.pcolormesh(X, Y, H_sm)\n",
        "    fig4.colorbar(im2, ax=ax)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    #%%\n",
        "    # import matplotlib.pyplot as plt\n",
        "\n",
        "    # fig4 = plt.figure(figsize=(7, 7))\n",
        "    # ax = fig4.add_subplot(111, aspect='auto')\n",
        "    # im = ax.pcolormesh(R[0], Th[0], F[0])\n",
        "    # fig4.colorbar(im, ax=ax)\n",
        "    # plt.show()\n",
        "\n",
        "    # X_col = data['x_col']\n",
        "    # fig2 = plt.figure(figsize=[8, 8], dpi=100)\n",
        "    # ax = plt.subplot(111)\n",
        "    # ax.plot(X_col[:, 0], X_col[:, 1], 'bx', linewidth=0.5)\n",
        "    # ax.set_ylabel('$x$', fontsize=15, rotation=0)\n",
        "    # ax.set_title('Function', fontsize=10)\n",
        "    # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z2RfbANAY2u"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import math\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "import abc\n",
        "import jax\n",
        "from jax import random, jit, vjp, grad, vmap, jacfwd, jacrev\n",
        "from jax.numpy.linalg import lstsq\n",
        "from jax.flatten_util import ravel_pytree\n",
        "# from customSampling import colloc2Dgrid_set, gaussian2D_smooth\n",
        "import time\n",
        "import functools\n",
        "from scipy.io import savemat, loadmat\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import pickle\n",
        "\n",
        "# find the root directory\n",
        "cluster = False\n",
        "if cluster:\n",
        "    rootdir = Path(__file__).parent\n",
        "else:\n",
        "    rootdir = Path(\"/content/drive/MyDrive/Stanford/2024_04_02\")\n",
        "# change JAX to double precision\n",
        "jax.config.update('jax_enable_x64', True)\n",
        "\n",
        "# initialize the neural network weights and biases\n",
        "def init_MLP(parent_key, layer_widths):\n",
        "    params = []\n",
        "    keys = random.split(parent_key, num=len(layer_widths) - 1)\n",
        "    # create the weights and biases for the network\n",
        "    for in_dim, out_dim, key in zip(layer_widths[:-1], layer_widths[1:], keys):\n",
        "        weight_key, bias_key = random.split(key)\n",
        "        xavier_stddev = jnp.sqrt(2 / (in_dim + out_dim))\n",
        "        weights = random.truncated_normal(weight_key, -2, 2, shape=(in_dim, out_dim)) * xavier_stddev\n",
        "        # print(f\"{jnp.std(weights)=}, {xavier_stddev=}\")\n",
        "        biases = random.truncated_normal(bias_key, -2, 2, shape=(out_dim,)) * 0\n",
        "        params.append(\n",
        "            [weights,\n",
        "             biases]\n",
        "        )\n",
        "    return params\n",
        "\n",
        "# define the basic formation of neural network\n",
        "def neural_net(params, z, limit, scl=60, act_s=1):\n",
        "    '''\n",
        "    :param params: weights and biases\n",
        "    :param x: input data [matrix with shape [N, m]]; m is number of inputs)\n",
        "    :param limit: characteristic scale for normalization [matrx with shape [2, m]]\n",
        "    :param sgn:  1 for even function and -1 for odd function\n",
        "    :return: neural network output [matrix with shape [N, n]]; n is number of outputs)\n",
        "    '''\n",
        "    lb = limit[0]  # lower bound for each input\n",
        "    ub = limit[1]  # upper bound for each input\n",
        "\n",
        "    # choose the activation function\n",
        "    actv = [jnp.tanh, jnp.sin][act_s]\n",
        "    # normalize the input\n",
        "    H = 2.0 * (z - lb) / (ub - lb) - 1.0\n",
        "    # separate the first, hidden and last layers\n",
        "    first, *hidden, last = params\n",
        "    # calculate the first layers output with right scale\n",
        "    H = actv(jnp.dot(H, first[0]) * scl + first[1])\n",
        "    # calculate the middle layers output\n",
        "    for layer in hidden:\n",
        "        H = jnp.tanh(jnp.dot(H, layer[0]) + layer[1])\n",
        "    # no activation function for last layer\n",
        "    var = jnp.dot(H, last[0]) + last[1]\n",
        "    return var\n",
        "\n",
        "# define the basic formation of neural network\n",
        "# multiply output by net_scl\n",
        "def fourier_net(params, z, limit, act_s, net_scl):\n",
        "    '''\n",
        "    :param params: weights and biases\n",
        "    :param x: input data [matrix with shape [N, m]]; m is number of inputs)\n",
        "    :param limit: characteristic scale for normalizeation [matrix with shape [2, m]]\n",
        "    :return: neural network output [matrix with shape [N, n]]; n is number of outputs)\n",
        "    '''\n",
        "    lb = limit[0]  # lower bound for each input\n",
        "    ub = limit[1]  # upper bound for each input\n",
        "\n",
        "    actv = [jnp.tanh, jnp.cos][act_s]\n",
        "    # normalize the input\n",
        "    H_full = 2.0 * (z - lb) / (ub - lb) - 1.0\n",
        "    print(f\"{H_full.shape}\")\n",
        "    # separate the first, hidden and last layers\n",
        "    first, *hidden, last = params\n",
        "    # calculate the first layers output with right scale\n",
        "    H = actv(jnp.dot(H, first[0]) * 2*np.pi + first[1]) * Ps_scl\n",
        "    # calculate the middle layers output\n",
        "    max_width = 31\n",
        "    for layer in hidden:\n",
        "        result0 = jnp.dot(H[:, :max_width], layer[0][:max_width])\n",
        "        for i in range(1, math.ceil(layer[0].shape[0] / max_width)):#int(jnp.ceil(layer[0].shape[0] / max_width))):\n",
        "            result0 = result0 + jnp.dot(H[:, i * max_width : (i + 1) * max_width], layer[0][i * max_width : (i + 1) * max_width])\n",
        "        # result = jnp.dot(H, layer[0])\n",
        "        # print(f\"{result.shape=}\")\n",
        "        # print(f\"{jnp.all(jnp.abs(result - result0) <= 0.00001)=}\")\n",
        "        H = jnp.tanh(result0 + layer[1])\n",
        "    # no activation function for last layer\n",
        "    # var = jnp.dot(H, jnp.ones([Ps.size, 1]))\n",
        "    var = jnp.dot(H, last[0]) + last[1]\n",
        "    return var * net_scl\n",
        "\n",
        "# generate weights and biases for all variables\n",
        "def sol_init_MLP(parent_key, layers):#n_hl, n_unit):\n",
        "    '''\n",
        "    :param n_hl: number of hidden layers [int]\n",
        "    :param n_unit: number of units in each layer [int]\n",
        "    '''\n",
        "    # layers = [Ps.size] + n_hl * [n_unit] + [1]\n",
        "    # generate the random key for each network\n",
        "    keys = random.split(parent_key, 1)\n",
        "    # generate weights and biases for\n",
        "    params_u = init_MLP(keys[0], layers)\n",
        "    return params_u\n",
        "\n",
        "# wrapper to create solution function with given domain size\n",
        "def sol_pred_create(limit, layers, act_s=1, net_scl = 1): # default activation is cos\n",
        "    '''\n",
        "    :param limit: domain size of the input\n",
        "    :return: function of the solution (a callable)\n",
        "    '''\n",
        "    def f_u(params, z):\n",
        "        # generate the NN\n",
        "        u = fourier_net(params, z, limit, act_s, net_scl)\n",
        "        return u\n",
        "    return f_u\n",
        "\n",
        "def mNN_pred_create(f_u, limit, scl, epsil, act_s=0):\n",
        "    '''\n",
        "    :param f_u: sum of previous stage network\n",
        "    :param limit: domain size of the input\n",
        "    :return: function of the solution (a callable)\n",
        "    '''\n",
        "    def f_comb(params, z):\n",
        "        # generate the NN\n",
        "        u_now = neural_net(params, z, limit, scl, act_s)\n",
        "        u = f_u(z) + epsil * u_now\n",
        "        return u\n",
        "    return f_comb\n",
        "\n",
        "\"\"\"Low-level functions developed for PINN training using JAX\"\"\"\n",
        "\n",
        "# # define the mean squared error\n",
        "# def ms_error(diff):\n",
        "#     return jnp.mean(jnp.square(diff), axis=0)\n",
        "\n",
        "\"\"\"Low-level functions developed for PINN training using JAX\"\"\"\n",
        "def lp2_error(diff, p):\n",
        "    # Returns (1/N * sum(|diff|^p))^(1/p) so it has the same order of magnitude as the RMSE\n",
        "    loss = jnp.power(jnp.mean(jnp.power(jnp.abs(diff), p), axis = 0), 1 / p)\n",
        "    return loss\n",
        "\n",
        "# generate matrix required for vjp for vector gradient\n",
        "def vgmat(z, n_out, idx=None):\n",
        "    '''\n",
        "    :param n_out: number of output variables\n",
        "    :param idx: indice (list) of the output variable to take the gradient\n",
        "    '''\n",
        "    if idx is None:\n",
        "        idx = range(n_out)\n",
        "    # obtain the number of index\n",
        "    n_idx = len(idx)\n",
        "    # obtain the number of input points\n",
        "    n_pt = z.shape[0]\n",
        "    # determine the shape of the gradient matrix\n",
        "    mat_shape = [n_idx, n_pt, n_out]\n",
        "    # create the zero matrix based on the shape\n",
        "    mat = jnp.zeros(mat_shape)\n",
        "    # choose the associated element in the matrix to 1\n",
        "    for l, ii in zip(range(n_idx), idx):\n",
        "        mat = mat.at[l, :, ii].set(1.)\n",
        "    return mat\n",
        "\n",
        "\n",
        "# vector gradient of the output with with input\n",
        "def vectgrad(func, z):\n",
        "    # obtain the output and the gradient function\n",
        "    sol, vjp_fn = vjp(func, z)\n",
        "    # determine the mat grad\n",
        "    mat = vgmat(z, sol.shape[1])\n",
        "    # calculate the gradient of each output with respect to each input\n",
        "    grad_sol = vmap(vjp_fn, in_axes=0)(mat)[0]\n",
        "    # calculate the total partial derivative of output with input\n",
        "    n_pd = z.shape[1] * sol.shape[1]\n",
        "    # reshape the derivative of output with input\n",
        "    grad_all = grad_sol.transpose(1, 0, 2).reshape(z.shape[0], n_pd)\n",
        "    return grad_all, sol\n",
        "\n",
        "\n",
        "def loss_create(predf_u, loss_ref, p = 2):\n",
        "    '''\n",
        "    a function factory to create the loss function based on given info\n",
        "    :param loss_ref: loss value at the initial of the training\n",
        "    :return: a loss function (callable)\n",
        "    '''\n",
        "    def res_fun(params, data):\n",
        "        # load the position and weight of collocation points\n",
        "        z_c = data['xy']\n",
        "        u_c = data['u']\n",
        "        # create the function for gradient calculation involves input Z only\n",
        "        f_u = lambda z: predf_u(params, z)\n",
        "        u_p = f_u(z_c)\n",
        "        res = (u_p - u_c)[:, 0]\n",
        "        return res\n",
        "\n",
        "    # loss function used for the PINN training\n",
        "    def loss_fun(params, data):\n",
        "\n",
        "        # load the position and weight of collocation points\n",
        "        z_c = data['xy']\n",
        "        u_c = data['u']\n",
        "\n",
        "        # create the function for gradient calculation involves input Z only\n",
        "        f_u = lambda z: predf_u(params, z)\n",
        "        u_p = f_u(z_c)\n",
        "\n",
        "        # load the hyper-parameter\n",
        "        lref = loss_fun.ref\n",
        "\n",
        "        # calculate the mean squared root error of normalization cond.\n",
        "        data_err = lp2_error(u_p - u_c, p)\n",
        "\n",
        "        # calculate the total loss\n",
        "        loss = jnp.sum(data_err)\n",
        "        loss_n = loss / lref\n",
        "        # group the loss of all conditions and equations\n",
        "        loss_info = jnp.array([lref, loss])\n",
        "        return loss_n, loss_info\n",
        "\n",
        "    loss_fun.ref = loss_ref\n",
        "    return loss_fun, res_fun\n",
        "\n",
        "#%%\n",
        "\n",
        "# create the Adam minimizer\n",
        "@functools.partial(jit, static_argnames=(\"lossf\", \"opt\"))\n",
        "def adam_minimizer(lossf, params, data, opt, opt_state):\n",
        "    \"\"\"Basic gradient update step based on the opt optimizer.\"\"\"\n",
        "    grads, loss_info = grad(lossf, has_aux=True)(params, data)\n",
        "    updates, opt_state = opt.update(grads, opt_state)\n",
        "    new_params = optax.apply_updates(params, updates)\n",
        "    return new_params, loss_info, opt_state\n",
        "\n",
        "def adam_optimizer(key, lossf, params, dataf, F0, epoch, lr=1e-3):\n",
        "    # select the Adam as the minimizer\n",
        "    opt_Adam = optax.adam(learning_rate=lr)\n",
        "    # obtain the initial state of the params\n",
        "    opt_state = opt_Adam.init(params)\n",
        "    # pre-allocate the loss varaible\n",
        "    loss_all = []\n",
        "    loss_return = []\n",
        "    data = dataf(key, F0)\n",
        "    new_key = random.split(key, 1)[0]\n",
        "\n",
        "    nc = jnp.int32(jnp.round(epoch / 5))\n",
        "    nc0 = 2500\n",
        "    # start the training iteration\n",
        "    for step in range(epoch):\n",
        "        # minimize the loss function using Adam\n",
        "        params, loss_info, opt_state = adam_minimizer(lossf, params, data, opt_Adam, opt_state)\n",
        "        # print the loss for every 100 iteration\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step: {step} | Loss: {loss_info[1]:.4e}\", file=sys.stderr)\n",
        "            new_key = random.split(key, 1)[0]\n",
        "        elif (step+1) % 500 == 0:\n",
        "            Fnew = predictF(params, dataf.X, dataf.Y)\n",
        "            data = dataf(new_key, Fnew)\n",
        "\n",
        "        # saving the loss\n",
        "        loss_all.append(loss_info[1:])\n",
        "        loss_return.append(loss_info[1].item())\n",
        "\n",
        "        if (step+1) % (2*nc0) == 0:\n",
        "            lossend = np.array(loss_all[-2 * nc0:])[:, 0]\n",
        "            lc1 = lossend[0: nc0]\n",
        "            lc2 = lossend[nc0:]\n",
        "            mm12 = jnp.abs(jnp.mean(lc1) - jnp.mean(lc2))\n",
        "            stdl2 = jnp.std(lc2)\n",
        "            # if the average loss improvement within 'nc' iteration is less than local loss fluctuation (std)\n",
        "            if mm12 / stdl2 < 0.4:\n",
        "                # reduce the learning rate by half\n",
        "                lr = lr / 2\n",
        "                opt_Adam = optax.adam(learning_rate=lr)\n",
        "            print(f\"learning rate for Adam: {lr:.4e} | mean: {mm12:.3e} | std: {stdl2:.3e}\", file=sys.stderr)\n",
        "\n",
        "    # obtain the total loss in the last iterations\n",
        "    lossend = jnp.array(loss_all[-nc:])[:, 0]\n",
        "    # find the minimum loss value\n",
        "    lmin = jnp.min(lossend)\n",
        "    # optain the last loss value\n",
        "    llast = lossend[-1]\n",
        "    # guarantee the loss value in last iteration is smaller than anyone before\n",
        "    for lc in range(2 * nc0):\n",
        "        if llast < lmin:\n",
        "            break\n",
        "        params, loss_info, opt_state = adam_minimizer(lossf, params, data, opt_Adam, opt_state)\n",
        "        llast = loss_info[0]\n",
        "        # saving the loss\n",
        "        loss_all.append(loss_info[0:])\n",
        "        loss_return.append(loss_info[1]) #TODO: check on this\n",
        "\n",
        "    print(f\"Step: final | Loss: {loss_info[1]:.4e}\", file=sys.stderr)\n",
        "\n",
        "    return params, loss_return #loss_all\n",
        "\n",
        "def gram_factory(v_residual):\n",
        "    def gramian(params, data):\n",
        "        # flatten params to enable correct jacobian compuations\n",
        "        f_params, unravel = ravel_pytree(params)\n",
        "        X = data['xy']\n",
        "        # For long flat jacobians we use reverse mode autodiff.\n",
        "        if len(f_params) > len(X):\n",
        "            jac = jacrev\n",
        "        # for tall slim jacobians we use forward mode autodiff.\n",
        "        else:\n",
        "            jac = jacfwd\n",
        "        # Compute the jacobian on batched data\n",
        "        J = jac(lambda f_params, x: v_residual(unravel(f_params), x), argnums=0)(f_params, data)\n",
        "\n",
        "        return 1.0 / len(X) * jnp.transpose(J) @ J\n",
        "    return gramian\n",
        "\n",
        "\"\"\" If we use the natural gradient descent without damping,\n",
        "then a linesearch spanning an extremly large variety of step sizes is needed.\n",
        "We do this using a line search on a logarithmic grid.\"\"\"\n",
        "\n",
        "def grid_line_search_factory(loss, steps):\n",
        "\n",
        "   def loss_at_step(step, data, params, tangent_params):\n",
        "      updated_params = [(w - step * dw, b - step * db)\n",
        "          for (w, b), (dw, db) in zip(params, tangent_params)]\n",
        "      return loss(updated_params, data)[0]\n",
        "\n",
        "   v_loss_at_steps = jit(vmap(loss_at_step, (0, None, None, None)))\n",
        "\n",
        "   @jit\n",
        "   def grid_line_search_update(params, data, tangent_params):\n",
        "      losses = v_loss_at_steps(steps, data, params, tangent_params)\n",
        "      step_size = steps[jnp.argmin(losses)]\n",
        "      return [(w - step_size * dw, b - step_size * db)\n",
        "              for (w, b), (dw, db) in zip(params, tangent_params)], step_size\n",
        "\n",
        "   return grid_line_search_update\n",
        "\n",
        "\n",
        "def ENG_optimizer(key, lossf, res_fun, params, dataf, epoch, div0):\n",
        "    # set up grid line search\n",
        "    grid = jnp.linspace(0, 30, 31)\n",
        "    steps = 0.5**grid\n",
        "    # gramian assembly requires flat parameters\n",
        "    f_params, unravel = ravel_pytree(params)\n",
        "    # create gramian initialization function\n",
        "    gram_int = jit(gram_factory(res_fun))\n",
        "    # sample the dataset\n",
        "    data = dataf(key)\n",
        "    new_key = random.split(key, 1)[0]\n",
        "    # set the initial damping\n",
        "    damping = 1e-1\n",
        "    div = div0\n",
        "\n",
        "    loss_all = []\n",
        "    step_all = []\n",
        "\n",
        "    for iter in range(epoch):\n",
        "        # compute gradient of loss\n",
        "        grads, loss_info = grad(lossf, has_aux=True)(params, data)\n",
        "        f_grads = ravel_pytree(grads)[0]\n",
        "\n",
        "        # calculate and save the current loss\n",
        "        loss_now = loss_info[1] / loss_info[0]\n",
        "        loss_all.append(loss_now)\n",
        "\n",
        "        # assemble gramian\n",
        "        G = gram_int(params, data)\n",
        "\n",
        "        # Marquardt-Levenberg (add damping effect)\n",
        "        Id = jnp.identity(len(G))\n",
        "        # G = jnp.max(jnp.array([loss_now, damping])) * Id + G\n",
        "        G = damping * Id + G\n",
        "\n",
        "        # compute natural gradient\n",
        "        f_nat_grad = lstsq(G, f_grads, rcond=-1)[0]\n",
        "        nat_grad = unravel(f_nat_grad)\n",
        "\n",
        "        ls_update = grid_line_search_factory(lossf, steps)\n",
        "        # one step of NGD\n",
        "        params, actual_step = ls_update(params, data, nat_grad)\n",
        "        step_all.append(actual_step)\n",
        "\n",
        "        if iter == 0:\n",
        "            loss0 = loss_now\n",
        "            iter0 = 0\n",
        "\n",
        "        if (iter+1) % 100 == 0 and iter > epoch-220:\n",
        "            new_key = random.split(new_key, 1)[0]\n",
        "            Fs = predictF(params, dataf.X, dataf.Y)\n",
        "            data = dataf(new_key, Fs)\n",
        "            plt.scatter(dataf.X, dataf.Y, c=Fs, s=10)\n",
        "            plt.gca().set_aspect(1.)\n",
        "            plt.gca().title.set_text('Fs')\n",
        "            plt.colorbar()\n",
        "            plt.show()\n",
        "            colpoint_plot(X*0, data['xy'], [-1, 1, -1, 1], ['collo. point', '$R$', '$\\theta$'])\n",
        "            div = 0.0001\n",
        "            damping = loss_now / div\n",
        "            loss0 = loss_now\n",
        "\n",
        "        if (iter + 1) % 5 == 0:\n",
        "            print(\n",
        "                f'NG Iteration: {iter + 1} with loss: {loss_info[1]:.4e} and'\n",
        "                f' step: {actual_step:.4e} and damping: {damping:.4e}'\n",
        "            )\n",
        "            ratio_loss = loss_now / loss0\n",
        "            if iter < 20:\n",
        "                if ratio_loss < 0.1 and actual_step > 0.02:\n",
        "                    damping = loss_now / div\n",
        "                    loss0 = loss_now\n",
        "                    iter0 = iter\n",
        "            elif iter >= 20:\n",
        "                if (ratio_loss < 0.1 and actual_step > 0.02) or (ratio_loss < 0.5 and actual_step > 0.1):\n",
        "                    ratio_step = step_all[-1] / step_all[-6]\n",
        "                    ratio_dloss = loss_all[-1] * loss_all[-11] / loss_all[-6] ** 2\n",
        "                    if ratio_step < 1 or ratio_dloss >= 4:\n",
        "                        gain = -jnp.log10(ratio_loss) / (iter - iter0)\n",
        "                        div = jnp.max(jnp.array([2, 6 + 2*jnp.log10(gain)]))\n",
        "                        damping /= div\n",
        "                        loss0 = loss_now\n",
        "\n",
        "    return params, loss_all\n",
        "\n",
        "\n",
        "#%%\n",
        "def data_eqsp2D(ds, ns):\n",
        "    '''\n",
        "    :param ds:  size of domain in the r direction\n",
        "    :param ns:  number of grid in each dimension len = 2\n",
        "    '''\n",
        "    x = jnp.linspace(ds[0], ds[1], ns[0])\n",
        "    y = jnp.linspace(ds[0], ds[1], ns[1])\n",
        "    X, Y = jnp.meshgrid(x, y)\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "\"\"\"Prepare the data points\"\"\"\n",
        "def data_func_create(N_col, N_bd = 10000, use_all = False):\n",
        "    # define the function that can re-sampling for each calling\n",
        "    # Domain bounds\n",
        "\n",
        "    bd = 0.95\n",
        "    idx_in = jnp.where((x_star < bd) & (x_star > -bd) & (y_star < bd) & (y_star > -bd))[0] # Within boundaries\n",
        "    idx_out = jnp.where((x_star >= bd) | (x_star <= -bd) | (y_star >= bd) | (y_star <= -bd))[0] # Outside of boundaries\n",
        "    F0 = X * 0 + 1\n",
        "\n",
        "    def dataf(key, F):\n",
        "        if use_all:\n",
        "            return dict(xy = xy_star, u = u_star)\n",
        "        else:\n",
        "            # generate the subkey for each group\n",
        "            new_keys = jax.random.split(key, 4)\n",
        "            # fix distribution collocation point\n",
        "            idx_c = jax.random.choice(new_keys[0], idx_in, (N_col[0],), replace=False) # collocation points\n",
        "            idx_b = jax.random.choice(new_keys[1], idx_out, (N_bd,), replace=False) # boundary points\n",
        "            idx_add = colloc2Dgrid_set(new_keys[2], X, Y, F, N_col[1])\n",
        "            idx_all = jnp.hstack([idx_c, idx_b, idx_add])\n",
        "            xy = xy_star[idx_all]\n",
        "            u_c = u_star[idx_all]\n",
        "            return dict(xy=xy, u=u_c)\n",
        "\n",
        "    dataf.X = X\n",
        "    dataf.Y = Y\n",
        "    return dataf, F0\n",
        "\n",
        "\n",
        "# plot the collocation point\n",
        "def colpoint_plot(U, X_col, limit, fig_str):\n",
        "    # limit = [x1min, x1max, x1min, x2max]\n",
        "    # fig_str = ['title', 'xlabel', 'yabel']\n",
        "\n",
        "    fig = plt.figure(figsize=[12, 10], dpi=100)\n",
        "\n",
        "    ax = plt.subplot()\n",
        "    h = ax.imshow(U, interpolation='nearest', cmap='rainbow',\n",
        "                  extent=limit, origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    fig.colorbar(h, cax=cax)\n",
        "\n",
        "    ax.plot(X_col[:, 0], X_col[:, 1], 'kx', markersize=5, clip_on=False)\n",
        "    ax.set_title(fig_str[0], fontsize=15)\n",
        "    ax.set_xlabel(fig_str[1], fontsize=15)\n",
        "    ax.set_ylabel(fig_str[2], fontsize=15, rotation=0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def predictF(params, z1, z2):\n",
        "    # create the output function\n",
        "    fsol = lambda z: pred_u(params, z)\n",
        "    # generate the input for network\n",
        "    z_star = jnp.hstack((z1.flatten()[:, None], z2.flatten()[:, None]))\n",
        "    # calculate the equation residue\n",
        "    f0 = fsol(z_star) - u_star\n",
        "\n",
        "    # calculate the maximum of the square of residue for all equations\n",
        "    f_sq = jnp.vstack(jnp.abs(f0))**1.5\n",
        "    # normalize the distribution function and add a basic level\n",
        "    f_nm = f_sq / jnp.mean(f_sq) + 0.5\n",
        "    # create the 2D distribution function F\n",
        "    F = jnp.reshape(f_nm, z1.shape)\n",
        "    # smooth the weight function by Gaussian filter\n",
        "    Fs = gaussian2D_smooth(F, [1, 1], [5, 5])\n",
        "    return Fs\n",
        "\n",
        "\"\"\"Set the conditions of the problem\"\"\"\n",
        "# select the random seed\n",
        "seed = 1234\n",
        "key = random.PRNGKey(seed)\n",
        "np.random.seed(seed)\n",
        "test = 3\n",
        "fourier_init = True\n",
        "\n",
        "# create the subkeys\n",
        "keys = random.split(key, 8)\n",
        "\n",
        "# select the size of neural network\n",
        "n_hl = 1\n",
        "n_unit = 30\n",
        "scl = 1\n",
        "lmt = jnp.array([[-1], [1]])\n",
        "p = 10\n",
        "act_s = 1\n",
        "\n",
        "# number of sampling points\n",
        "N_col = jnp.int32([2.5e4, 2.5e4])\n",
        "\n",
        "# set the training iteration\n",
        "epoch1 = 1\n",
        "\n",
        "if test == 1:\n",
        "    if cluster:\n",
        "        FileName = 'Reg_ENG_exp2.mat'\n",
        "    else:\n",
        "        FileName = '/content/drive/MyDrive/Stanford/2024_04_02/Reg_ENG_exp2.mat'\n",
        "    data = loadmat(FileName)\n",
        "    X = data['X']\n",
        "    Y = data['Y']\n",
        "    U = data['e']\n",
        "\n",
        "# U = jnp.sin(2*np.pi*(2*X+Y))   # other simple examples to test\n",
        "# U = jnp.exp(-Y**2)\n",
        "# U = X\n",
        "if test == 2:\n",
        "    if cluster:\n",
        "        FileName = \"N=512_Re=2000_mcwilliams_save_every=16000_num_steps=1.npz\"\n",
        "    else:\n",
        "        FileName = \"/content/drive/MyDrive/Stanford/2024_04_02/N=512_Re=2000_mcwilliams_save_every=16000_num_steps=1.npz\"\n",
        "    endpoint = False\n",
        "    N_x = 512\n",
        "    N_y = 512\n",
        "    lb = [-1, -1]\n",
        "    ub = [1, 1]\n",
        "    limit = jnp.array([lb, ub])\n",
        "    x = jnp.linspace(-1, 1, N_x, endpoint = endpoint) #jnp.linspace(0, 1, N_x)\n",
        "    y = jnp.linspace(-1, 1, N_y, endpoint = endpoint) #jnp.linspace(-1, 1, N_y)\n",
        "    X, Y = jnp.meshgrid(x, y)\n",
        "    U = jnp.load(FileName)['psi'][-1]\n",
        "\n",
        "if test == 3:\n",
        "    endpoint = False\n",
        "    N_x = 30\n",
        "    N_y = 30\n",
        "    lb = [-1, -1]\n",
        "    ub = [1, 1]\n",
        "    limit = jnp.array([lb, ub])\n",
        "    x = jnp.linspace(-1, 1, N_x, endpoint = endpoint) #jnp.linspace(0, 1, N_x)\n",
        "    y = jnp.linspace(-1, 1, N_y, endpoint = endpoint) #jnp.linspace(-1, 1, N_y)\n",
        "    X, Y = jnp.meshgrid(x, y)\n",
        "    U = 3 * jnp.sin(2 * np.pi * X + Y + 3)\n",
        "\n",
        "if test == 4:\n",
        "    endpoint = False\n",
        "    N_x = 512\n",
        "    N_y = 512\n",
        "    lb = [-1, -1]\n",
        "    ub = [1, 1]\n",
        "    limit = jnp.array([lb, ub])\n",
        "    x = jnp.linspace(-1, 1, N_x, endpoint = endpoint) #jnp.linspace(0, 1, N_x)\n",
        "    y = jnp.linspace(-1, 1, N_y, endpoint = endpoint) #jnp.linspace(-1, 1, N_y)\n",
        "    X, Y = jnp.meshgrid(x, y)\n",
        "    U = loadmat(\"/content/drive/MyDrive/Stanford/2024_04_06/reg2d_test2_p10_iters50000_stage1_fourinitTrue_act1_3000_residual.mat\")['residual']\n",
        "\n",
        "U_0 = U\n",
        "n_stages = 4\n",
        "U_p_stages = [] # list of all the predicted Us for each stage\n",
        "eps_stages = [] # epsilon for each stage\n",
        "loss_stages = [] # list of all losses\n",
        "for stage in range(n_stages):\n",
        "    eps = jnp.max(U)\n",
        "    U = U / eps\n",
        "    x_star = X.flatten()[:, jnp.newaxis]\n",
        "    y_star = Y.flatten()[:, jnp.newaxis]\n",
        "    u_star = U.flatten()[:, jnp.newaxis]\n",
        "    xy_star = jnp.hstack((x_star, y_star))\n",
        "\n",
        "    # plt.scatter(X, Y, c=U, s=10)\n",
        "    # plt.gca().set_aspect(1.)\n",
        "    # plt.gca().title.set_text('Fs')\n",
        "    # plt.colorbar()\n",
        "    # plt.show()\n",
        "\n",
        "    w = jnp.fft.fft2(U)\n",
        "    w = w.at[1::2, :].set(w[1::2, :]*jnp.exp(1j*np.pi))  # shift the solution by half period\n",
        "    w = w.at[:, 1::2].set(w[:, 1::2]*jnp.exp(1j*np.pi))  # shift the solution by half period\n",
        "\n",
        "    timestep = jnp.array([N_x, N_y]) / (limit[1] - limit[0])\n",
        "    freq_x = jnp.fft.fftfreq(n = N_x, d = 1 / timestep[0]) # frequency in multiples of 1/pi cycles/second\n",
        "    freq_y = jnp.fft.fftfreq(n = N_y, d = 1 / timestep[1])\n",
        "    plt.figure()\n",
        "    h = plt.pcolormesh(jnp.fft.fftshift(freq_x), jnp.fft.fftshift(freq_y), np.abs(jnp.fft.fftshift(w)), shading = 'auto')\n",
        "    plt.colorbar(h)\n",
        "    plt.show()\n",
        "    plt.close('all')\n",
        "\n",
        "    # ax = fig.add_subplot(3, 3, 2)\n",
        "    # timestep = jnp.array([N_x, N_y]) / (limit[1] - limit[0])\n",
        "    # freq_x = jnp.fft.fftshift(jnp.fft.fftfreq(n = N_x, d = 1 / timestep[0])) # frequency in multiples of 1/pi cycles/second\n",
        "    # freq_y = jnp.fft.fftshift(jnp.fft.fftfreq(n = N_y, d = 1 / timestep[1]))\n",
        "    # norm = 'forward'\n",
        "    # FS = jnp.fft.fftn(u_target, norm = norm)\n",
        "    # FS_abs = np.abs(np.fft.fftshift(FS))\n",
        "    # h = ax.pcolormesh(freq_x, freq_y, np.abs(np.fft.fftshift(FS)), shading = \"auto\")\n",
        "    # plt.colorbar(h, ax = ax)\n",
        "\n",
        "    # L = N_x             # Length of signal\n",
        "    # Fs = L/2            # Sampling frequency\n",
        "    # f1 = Fs * jnp.hstack([jnp.arange(0, L/2+1), jnp.arange(-L/2+1, 0)])/L\n",
        "    # F1, F2 = jnp.meshgrid(f1, f1)\n",
        "    # F11, F21 = jnp.meshgrid(freq_x, freq_y)\n",
        "    # print(f\"{jnp.all(F1==F11)=}\")\n",
        "    # plt.figure()\n",
        "    # h = plt.pcolormesh(F1 - F11, shading = 'auto')\n",
        "    # plt.colorbar(h)\n",
        "    # plt.show()\n",
        "    # plt.close('all')\n",
        "    FX, FY = jnp.meshgrid(freq_x, freq_y)\n",
        "\n",
        "    ds = 200\n",
        "    wc = jnp.hstack([w[0:ds, -ds+1:], w[0:ds, 0:ds]])\n",
        "    wc = wc.at[0:1, :].set(wc[0:1, :]/2)\n",
        "    F1c = jnp.hstack([FX[0:ds, -ds+1:], FX[0:ds, 0:ds]])\n",
        "    F2c = jnp.hstack([FY[0:ds, -ds+1:], FY[0:ds, 0:ds]])\n",
        "\n",
        "    P2c = jnp.abs(wc/N_x**2*2)\n",
        "    A2c = jnp.angle(wc/N_x**2*2)\n",
        "\n",
        "    P_1d = P2c.flatten()\n",
        "    A_1d = A2c.flatten()\n",
        "    F1_1d = F1c.flatten()\n",
        "    F2_1d = F2c.flatten()\n",
        "\n",
        "    idx = jnp.flip(jnp.argsort(P_1d))\n",
        "    Ps = P_1d[idx]\n",
        "    idxElim = jnp.where(Ps < Ps[0]*0.0001)[0]\n",
        "    idxs = jnp.delete(idx, idxElim)\n",
        "\n",
        "    Ps = P_1d[idxs]\n",
        "    As = A_1d[idxs]\n",
        "    F1s = F1_1d[idxs]\n",
        "    F2s = F2_1d[idxs]\n",
        "\n",
        "    # determine the number of mode you need\n",
        "    nmode = jnp.min(jnp.array([2000, Ps.size]))\n",
        "    print(f\"{nmode=}\")\n",
        "    Ps = Ps[:nmode][jnp.newaxis,:]\n",
        "    As = As[:nmode][jnp.newaxis,:]\n",
        "    F1s = F1s[:nmode][jnp.newaxis,:]\n",
        "    F2s = F2s[:nmode][jnp.newaxis,:]\n",
        "\n",
        "    wgh0_s = jnp.vstack([F1s, F2s])\n",
        "    bia0_s = As\n",
        "    first_params = [wgh0_s, bia0_s]\n",
        "    Ps_scl = Ps / jnp.max(Ps) # TODO: ask why we do jnp.max(Ps)\n",
        "\n",
        "\n",
        "    #%% second stage training\n",
        "\n",
        "    if fourier_init:\n",
        "        # initialize the weights and biases of the network\n",
        "        layers = [Ps.size] + n_hl * [n_unit] + [1]\n",
        "        print(f\"{layers=}\")\n",
        "        trained_params0 = sol_init_MLP(keys[5], layers)# n_hl, n_unit)\n",
        "        trained_params = [first_params] + trained_params0\n",
        "    else:\n",
        "        layers = [2] + [Ps.size] + n_hl * [n_unit] + [1]\n",
        "        trained_params = sol_init_MLP(keys[5], layers) #n_hl, n_unit)\n",
        "\n",
        "    # create the solution function\n",
        "    pred_u = sol_pred_create(lmt, layers = layers, act_s = act_s)\n",
        "    # create the data function\n",
        "    dataf, F0 = data_func_create(N_col, use_all = True)\n",
        "\n",
        "    F = predictF(trained_params, dataf.X, dataf.Y)\n",
        "    # print(\"hi\")\n",
        "    data = dataf(keys[4], F)\n",
        "    #\n",
        "    colpoint_plot(F, data['xy'], [-1, 1, -1, 1], ['collo. point', '$R$', '$\\theta$'])\n",
        "\n",
        "    # create the solution function\n",
        "    f_u = lambda z: pred_u(trained_params, z)\n",
        "    u_p = f_u(xy_star)\n",
        "    U_p = jnp.reshape(u_p, X.shape)\n",
        "    net_scl = 1 / jnp.max(U_p)\n",
        "\n",
        "    # create the solution function\n",
        "    pred_u = sol_pred_create(lmt, layers = layers, act_s = act_s, net_scl = net_scl)\n",
        "    f_u = lambda z: pred_u(trained_params, z)\n",
        "    u_p = f_u(xy_star)\n",
        "    U_p = jnp.reshape(u_p, X.shape)\n",
        "\n",
        "    # plt.scatter(X, Y, c=U_p, s=10)\n",
        "    # plt.gca().set_aspect(1.)\n",
        "    # plt.gca().title.set_text('Fs')\n",
        "    # plt.colorbar()\n",
        "    # plt.show()\n",
        "\n",
        "    # calculate the loss function\n",
        "    NN_loss, res_fun = loss_create(pred_u, loss_ref=1, p = p)\n",
        "    NN_loss.ref = NN_loss(trained_params, data)[1][1]\n",
        "\n",
        "    if cluster:\n",
        "        description = f'2024_04_06/reg2d_test{test}_p{p}_iters{epoch1}_stage{stage}_fourinit{fourier_init}_act{act_s}_nmode{nmode}'\n",
        "    else:\n",
        "        description = f'reg2d_test{test}_p{p}_iters{epoch1}_stage{stage}'\n",
        "    def plot_results(U, U_p, loss = None, stage = \"\", filename = \"reg2d_results.png\", title = \"Results\"):\n",
        "        U = U\n",
        "        U_p = U_p\n",
        "        dpi = 200\n",
        "        fig = plt.figure(figsize = [9, 9], dpi = dpi)\n",
        "\n",
        "        u_target = U.reshape(N_y, N_x)\n",
        "        u_pred = U_p.reshape(N_y, N_x)\n",
        "        u_min = min(jnp.min(u_target), jnp.min(u_pred))\n",
        "        u_max = max(jnp.max(u_target), jnp.max(u_pred))\n",
        "        error = u_target - u_pred\n",
        "        err_min = jnp.min(error)\n",
        "        err_max = jnp.max(error)\n",
        "        axis_fontsize = 10\n",
        "\n",
        "        # Target\n",
        "        ax = fig.add_subplot(3, 3, 1)\n",
        "        ax.set_xlabel('x', fontsize = axis_fontsize)\n",
        "        ax.set_ylabel('y', fontsize = axis_fontsize)\n",
        "        ax.set_title('Target function', fontsize = axis_fontsize)\n",
        "        ax.set_aspect('equal')\n",
        "        h = ax.contourf(X, Y, u_target, levels = 100, cmap = 'jet', vmin = u_min, vmax = u_max)\n",
        "        plt.colorbar(h, ax = ax)\n",
        "\n",
        "        # Plot model prediction\n",
        "        ax = fig.add_subplot(3, 3, 4)\n",
        "        ax.set_xlabel('x', fontsize = axis_fontsize)\n",
        "        ax.set_ylabel('y', fontsize = axis_fontsize)\n",
        "        ax.set_title(f'Model prediction', fontsize = axis_fontsize)\n",
        "        h = ax.contourf(X, Y, u_pred, levels = 100, cmap = 'jet', vmin = u_min, vmax = u_max)\n",
        "        ax.set_aspect('equal')\n",
        "        plt.colorbar(h, ax = ax)\n",
        "\n",
        "        # Plot error\n",
        "        ax = fig.add_subplot(3, 3, 7)\n",
        "        ax.set_xlabel('x', fontsize = axis_fontsize)\n",
        "        ax.set_ylabel('y', fontsize = axis_fontsize)\n",
        "        ax.set_title('Error', fontsize = axis_fontsize)\n",
        "        h = ax.contourf(X, Y, error, levels = 100, cmap = 'jet', vmin = err_min, vmax = err_max)\n",
        "        ax.set_aspect('equal')\n",
        "        plt.colorbar(h, ax = ax)\n",
        "\n",
        "        # Frequencies of actual solution\n",
        "        ax = fig.add_subplot(3, 3, 2)\n",
        "        timestep = jnp.array([N_x, N_y]) / (limit[1] - limit[0])\n",
        "        freq_x = jnp.fft.fftshift(jnp.fft.fftfreq(n = N_x, d = 1 / timestep[0])) # frequency in multiples of 1/pi cycles/second\n",
        "        freq_y = jnp.fft.fftshift(jnp.fft.fftfreq(n = N_y, d = 1 / timestep[1]))\n",
        "        norm = 'forward'\n",
        "        FS = jnp.fft.fftn(u_target, norm = norm)\n",
        "        FS_abs = np.abs(np.fft.fftshift(FS))\n",
        "        h = ax.pcolormesh(freq_x, freq_y, np.abs(np.fft.fftshift(FS)), shading = \"auto\")\n",
        "        plt.colorbar(h, ax = ax)\n",
        "\n",
        "        f_max = 100\n",
        "        ax.set_xlim(xmin = -1 * f_max, xmax = f_max)\n",
        "        # ax.set_ylim(ymin = 0, ymax = f_max)\n",
        "        ax.set_ylim(ymin = -1 * f_max, ymax = f_max)\n",
        "        ax.set_title('Target frequencies', fontsize = axis_fontsize)\n",
        "        ax.set_aspect('equal')\n",
        "\n",
        "        # Frequencies of predicted solution\n",
        "        ax = fig.add_subplot(3, 3, 5)\n",
        "        FS = jnp.fft.fftn(u_pred, norm = norm)\n",
        "        FS_abs = np.abs(np.fft.fftshift(FS))\n",
        "        ax.set_aspect('equal')\n",
        "        print(f\"{FS_abs.min()}, {FS_abs.max()}\")\n",
        "        h = ax.pcolormesh(freq_x, freq_y, FS_abs, shading = \"auto\")#, norm = mpl.colors.LogNorm(vmin=FS_abs.min(), vmax=FS_abs.max()))\n",
        "        plt.colorbar(h, ax = ax)\n",
        "        ax.set_xlim(xmin = -1 * f_max, xmax = f_max)\n",
        "        ax.set_ylim(ymin = -1 * f_max, ymax = f_max)\n",
        "        ax.set_title('Predicted frequencies', fontsize = axis_fontsize)\n",
        "        ax.set_aspect('equal')\n",
        "\n",
        "        # Frequencies of error\n",
        "        ax = fig.add_subplot(3, 3, 8)\n",
        "        FS = jnp.fft.fftn(error, norm = norm)\n",
        "        FS_abs = np.abs(np.fft.fftshift(FS))\n",
        "        argmax = np.unravel_index(FS_abs.argmax(), FS_abs.shape)\n",
        "\n",
        "        h = ax.pcolormesh(freq_x, freq_y, np.abs(np.fft.fftshift(FS)), shading = \"auto\")\n",
        "        plt.colorbar(h, ax = ax)\n",
        "        ax.set_xlim(xmin = -1 * f_max, xmax = f_max)\n",
        "        ax.set_ylim(ymin = -1 * f_max, ymax = f_max)\n",
        "        ax.set_title('error frequencies', fontsize = axis_fontsize)\n",
        "        ax.set_aspect('equal')\n",
        "\n",
        "                # Energy spectrum of actual solution\n",
        "        ax = fig.add_subplot(3, 3, 3)\n",
        "        KX, KY = jnp.meshgrid(freq_x, freq_y)\n",
        "        k2 = KX ** 2 + KY ** 2 # wave number squared\n",
        "        psihat = jnp.fft.fftshift(jnp.fft.fft2(U))\n",
        "        tke = jnp.real(.5 * k2 * psihat * jnp.conj(psihat))\n",
        "        kmod = jnp.sqrt(k2)\n",
        "        k = jnp.arange(1, psihat.shape[0] // 2 + 1, 1, dtype=jnp.float64) # nyquist limit for this grid\n",
        "        E = jnp.zeros_like(k)\n",
        "        res = 200 # resolution\n",
        "        dk = (jnp.max(k) - jnp.min(k)) / res\n",
        "\n",
        "            #  binning energies with wavenumber modulus in threshold\n",
        "        for i in range(len(k)):\n",
        "            E = E.at[i].add(jnp.sum(tke[(kmod < k[i] + dk) & (kmod >= k[i] - dk)]))\n",
        "        sum_E = jnp.sum(E)\n",
        "            # angle averaged Turbulent Kinetic Energy spectrum\n",
        "        ax.loglog(k, E, '-k', label = \"Target E(k)\")\n",
        "        ax.set_xlabel(\"k\")\n",
        "        ax.set_ylabel(\"E(k)\")\n",
        "        ax.legend()\n",
        "\n",
        "        # Energy spectrum of predicted solution\n",
        "        psihat = jnp.fft.fftshift(jnp.fft.fft2(U_p))\n",
        "        tke = jnp.real(.5 * k2 * psihat * jnp.conj(psihat))\n",
        "        kmod = jnp.sqrt(k2)\n",
        "        k = jnp.arange(1, psihat.shape[0] // 2 + 1, 1, dtype=jnp.float64) # nyquist limit for this grid\n",
        "        E = jnp.zeros_like(k)\n",
        "        res = 200 # resolution\n",
        "        dk = (jnp.max(k) - jnp.min(k)) / res\n",
        "\n",
        "            #  binning energies with wavenumber modulus in threshold\n",
        "        for i in range(len(k)):\n",
        "            E = E.at[i].add(jnp.sum(tke[(kmod < k[i] + dk) & (kmod >= k[i] - dk)]))\n",
        "        sum_E = jnp.sum(E)\n",
        "            # angle averaged Turbulent Kinetic Energy spectrum\n",
        "        ax.loglog(k, E, '-b', label = \"Predicted E(k)\")\n",
        "        ax.set_xlabel(\"k\")\n",
        "        ax.set_ylabel(\"E(k)\")\n",
        "        ax.legend()\n",
        "\n",
        "        # Energy spectrum of error\n",
        "        ax = fig.add_subplot(3, 3, 9)\n",
        "        psihat = jnp.fft.fftshift(jnp.fft.fft2(U - U_p))\n",
        "        tke = jnp.real(.5 * k2 * psihat * jnp.conj(psihat))\n",
        "        kmod = jnp.sqrt(k2)\n",
        "        k = jnp.arange(1, psihat.shape[0] // 2 + 1, 1, dtype=jnp.float64) # nyquist limit for this grid\n",
        "        E = jnp.zeros_like(k)\n",
        "        res = 200 # resolution\n",
        "        dk = (jnp.max(k) - jnp.min(k)) / res\n",
        "\n",
        "            #  binning energies with wavenumber modulus in threshold\n",
        "        for i in range(len(k)):\n",
        "            E = E.at[i].add(jnp.sum(tke[(kmod < k[i] + dk) & (kmod >= k[i] - dk)]))\n",
        "        sum_E = jnp.sum(E)\n",
        "            # angle averaged Turbulent Kinetic Energy spectrum\n",
        "        ax.loglog(k, E, '-b', label = \"Error E(k)\")\n",
        "        ax.set_xlabel(\"k\")\n",
        "        ax.set_ylabel(\"E(k)\")\n",
        "        ax.legend()\n",
        "\n",
        "\n",
        "        # Loss\n",
        "        if loss is not None:\n",
        "            ax = fig.add_subplot(3, 3, 6)\n",
        "            ax.set_ylabel(\"Loss\", fontsize = axis_fontsize, rotation = 90)\n",
        "            ax.set_yscale('log')\n",
        "            n = 0\n",
        "            # Plot loss, labeled by optimization method\n",
        "            for i, loss_i in enumerate(loss):\n",
        "                n_iter = len(loss_i)\n",
        "                if len(loss) == 1:\n",
        "                    ax.plot(jnp.arange(n, n + n_iter), loss_i, '-', linewidth = 2, label = f\"Stage {stage} Loss\")\n",
        "                else:\n",
        "                    ax.plot(jnp.arange(n, n + n_iter), loss_i, '-', linewidth = 2, label = f\"Stage {i} Loss\")\n",
        "                n += n_iter\n",
        "            ax.legend()\n",
        "\n",
        "        # plt.tight_layout()\n",
        "        fig.suptitle(title)\n",
        "        fig.tight_layout()\n",
        "        plt.savefig(filename)\n",
        "        plt.show()\n",
        "        plt.close('all')\n",
        "    plot_results(U * eps, U_p * eps, loss = None, stage = stage, filename = f'{description}_init.png', title = f\"Stage {stage} Initialization\")\n",
        "\n",
        "    \"\"\"Training using Adam\"\"\"\n",
        "    # set the learning rate for Adam\n",
        "    lr = 1e-3\n",
        "    # training the neural network\n",
        "    start_time = time.time()\n",
        "    trained_params, loss1 = adam_optimizer(keys[6], NN_loss, trained_params, dataf, F, epoch1, lr=lr)\n",
        "    # plt.figure()\n",
        "    # plt.yscale(\"log\")\n",
        "    # plt.plot(loss1)\n",
        "    # plt.title(\"Loss\")\n",
        "    # plt.savefig(f\"reg2d_stage{stage}_loss.png\")\n",
        "\n",
        "    # create the solution function\n",
        "    f_u = lambda z: pred_u(trained_params, z)\n",
        "    u_p = f_u(xy_star)\n",
        "    U_p = jnp.reshape(u_p, X.shape)\n",
        "\n",
        "    loss1 = jnp.array(loss1) * eps\n",
        "    loss_stages.append(loss1)\n",
        "\n",
        "    U = U * eps\n",
        "    U_p = U_p * eps\n",
        "    plot_results(U, U_p, loss = [loss1], stage = stage, filename = f'{description}_results.png', title = f\"Stage {stage} Results\")\n",
        "\n",
        "    error = U - U_p\n",
        "    mdic = {\"X\": np.array(X), \"Y\": np.array(Y), \"e\": np.array(error),\n",
        "            \"U\": np.array(U), \"U_p\": np.array(U_p), \"eps\": eps, \"loss\": loss1}\n",
        "    FileName = f'{description}_results.mat'\n",
        "    savemat(FileName, mdic)\n",
        "    with open(f\"{description}_params.pickle\", 'wb') as f:\n",
        "        pickle.dump(trained_params, f)\n",
        "    U_p_stages.append(U_p)\n",
        "    eps_stages.append(eps)\n",
        "\n",
        "    U_p_total = jnp.sum(jnp.array(U_p_stages), axis = 0)\n",
        "    plot_results(U_0, U_p_total, loss = loss_stages, stage = stage, filename = f'{description}_total_results.png', title = f\"Stage {stage} Total Results\")\n",
        "\n",
        "    U = error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot sum\n",
        "def plot_results(U, U_p, loss = None, stage = \"\", filename = \"reg2d_results.png\", title = \"Results\"):\n",
        "    U = U\n",
        "    U_p = U_p\n",
        "    dpi = 200\n",
        "    fig = plt.figure(figsize = [9, 9], dpi = dpi)\n",
        "\n",
        "    u_target = U.reshape(N_y, N_x)\n",
        "    u_pred = U_p.reshape(N_y, N_x)\n",
        "    u_min = min(jnp.min(u_target), jnp.min(u_pred))\n",
        "    u_max = max(jnp.max(u_target), jnp.max(u_pred))\n",
        "    error = u_target - u_pred\n",
        "    err_min = jnp.min(error)\n",
        "    err_max = jnp.max(error)\n",
        "    axis_fontsize = 10\n",
        "\n",
        "    # Target\n",
        "    ax = fig.add_subplot(3, 3, 1)\n",
        "    ax.set_xlabel('x', fontsize = axis_fontsize)\n",
        "    ax.set_ylabel('y', fontsize = axis_fontsize)\n",
        "    ax.set_title('Target function', fontsize = axis_fontsize)\n",
        "    ax.set_aspect('equal')\n",
        "    h = ax.contourf(X, Y, u_target, levels = 100, cmap = 'jet', vmin = u_min, vmax = u_max)\n",
        "    plt.colorbar(h, ax = ax)\n",
        "\n",
        "    # Plot model prediction\n",
        "    ax = fig.add_subplot(3, 3, 4)\n",
        "    ax.set_xlabel('x', fontsize = axis_fontsize)\n",
        "    ax.set_ylabel('y', fontsize = axis_fontsize)\n",
        "    ax.set_title(f'Model prediction', fontsize = axis_fontsize)\n",
        "    h = ax.contourf(X, Y, u_pred, levels = 100, cmap = 'jet', vmin = u_min, vmax = u_max)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.colorbar(h, ax = ax)\n",
        "\n",
        "    # Plot error\n",
        "    ax = fig.add_subplot(3, 3, 7)\n",
        "    ax.set_xlabel('x', fontsize = axis_fontsize)\n",
        "    ax.set_ylabel('y', fontsize = axis_fontsize)\n",
        "    ax.set_title('Error', fontsize = axis_fontsize)\n",
        "    h = ax.contourf(X, Y, error, levels = 100, cmap = 'jet', vmin = err_min, vmax = err_max)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.colorbar(h, ax = ax)\n",
        "\n",
        "    # Frequencies of actual solution\n",
        "    ax = fig.add_subplot(3, 3, 2)\n",
        "    timestep = jnp.array([N_x, N_y]) / (limit[1] - limit[0])\n",
        "    freq_x = jnp.fft.fftshift(jnp.fft.fftfreq(n = N_x, d = 1 / timestep[0])) # frequency in multiples of 1/pi cycles/second\n",
        "    freq_y = jnp.fft.fftshift(jnp.fft.fftfreq(n = N_y, d = 1 / timestep[1]))\n",
        "    norm = 'forward'\n",
        "    FS = jnp.fft.fftn(u_target, norm = norm)\n",
        "    FS_abs = np.abs(np.fft.fftshift(FS))\n",
        "    h = ax.pcolormesh(freq_x, freq_y, np.abs(np.fft.fftshift(FS)), shading = \"auto\")\n",
        "    plt.colorbar(h, ax = ax)\n",
        "\n",
        "    f_max = 100\n",
        "    ax.set_xlim(xmin = -1 * f_max, xmax = f_max)\n",
        "    # ax.set_ylim(ymin = 0, ymax = f_max)\n",
        "    ax.set_ylim(ymin = -1 * f_max, ymax = f_max)\n",
        "    ax.set_title('Target frequencies', fontsize = axis_fontsize)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "    # Frequencies of predicted solution\n",
        "    ax = fig.add_subplot(3, 3, 5)\n",
        "    FS = jnp.fft.fftn(u_pred, norm = norm)\n",
        "    FS_abs = np.abs(np.fft.fftshift(FS))\n",
        "    ax.set_aspect('equal')\n",
        "    print(f\"{FS_abs.min()}, {FS_abs.max()}\")\n",
        "    h = ax.pcolormesh(freq_x, freq_y, FS_abs, shading = \"auto\")#, norm = mpl.colors.LogNorm(vmin=FS_abs.min(), vmax=FS_abs.max()))\n",
        "    plt.colorbar(h, ax = ax)\n",
        "    ax.set_xlim(xmin = -1 * f_max, xmax = f_max)\n",
        "    ax.set_ylim(ymin = -1 * f_max, ymax = f_max)\n",
        "    ax.set_title('Predicted frequencies', fontsize = axis_fontsize)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "    # Frequencies of error\n",
        "    ax = fig.add_subplot(3, 3, 8)\n",
        "    FS = jnp.fft.fftn(error, norm = norm)\n",
        "    FS_abs = np.abs(np.fft.fftshift(FS))\n",
        "    argmax = np.unravel_index(FS_abs.argmax(), FS_abs.shape)\n",
        "\n",
        "    h = ax.pcolormesh(freq_x, freq_y, np.abs(np.fft.fftshift(FS)), shading = \"auto\")\n",
        "    plt.colorbar(h, ax = ax)\n",
        "    ax.set_xlim(xmin = -1 * f_max, xmax = f_max)\n",
        "    ax.set_ylim(ymin = -1 * f_max, ymax = f_max)\n",
        "    ax.set_title('error frequencies', fontsize = axis_fontsize)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "            # Energy spectrum of actual solution\n",
        "    ax = fig.add_subplot(3, 3, 3)\n",
        "    KX, KY = jnp.meshgrid(freq_x, freq_y)\n",
        "    k2 = KX ** 2 + KY ** 2 # wave number squared\n",
        "    psihat = jnp.fft.fftshift(jnp.fft.fft2(U))\n",
        "    tke = jnp.real(.5 * k2 * psihat * jnp.conj(psihat))\n",
        "    kmod = jnp.sqrt(k2)\n",
        "    k = jnp.arange(1, psihat.shape[0] // 2 + 1, 1, dtype=jnp.float64) # nyquist limit for this grid\n",
        "    E = jnp.zeros_like(k)\n",
        "    res = 200 # resolution\n",
        "    dk = (jnp.max(k) - jnp.min(k)) / res\n",
        "\n",
        "        #  binning energies with wavenumber modulus in threshold\n",
        "    for i in range(len(k)):\n",
        "        E = E.at[i].add(jnp.sum(tke[(kmod < k[i] + dk) & (kmod >= k[i] - dk)]))\n",
        "    sum_E = jnp.sum(E)\n",
        "        # angle averaged Turbulent Kinetic Energy spectrum\n",
        "    ax.loglog(k, E, '-k', label = \"Target E(k)\")\n",
        "    ax.set_xlabel(\"k\")\n",
        "    ax.set_ylabel(\"E(k)\")\n",
        "    ax.legend()\n",
        "\n",
        "    # Energy spectrum of predicted solution\n",
        "    psihat = jnp.fft.fftshift(jnp.fft.fft2(U_p))\n",
        "    tke = jnp.real(.5 * k2 * psihat * jnp.conj(psihat))\n",
        "    kmod = jnp.sqrt(k2)\n",
        "    k = jnp.arange(1, psihat.shape[0] // 2 + 1, 1, dtype=jnp.float64) # nyquist limit for this grid\n",
        "    E = jnp.zeros_like(k)\n",
        "    res = 200 # resolution\n",
        "    dk = (jnp.max(k) - jnp.min(k)) / res\n",
        "\n",
        "        #  binning energies with wavenumber modulus in threshold\n",
        "    for i in range(len(k)):\n",
        "        E = E.at[i].add(jnp.sum(tke[(kmod < k[i] + dk) & (kmod >= k[i] - dk)]))\n",
        "    sum_E = jnp.sum(E)\n",
        "        # angle averaged Turbulent Kinetic Energy spectrum\n",
        "    ax.loglog(k, E, '-b', label = \"Predicted E(k)\")\n",
        "    ax.set_xlabel(\"k\")\n",
        "    ax.set_ylabel(\"E(k)\")\n",
        "    ax.legend()\n",
        "\n",
        "    # Energy spectrum of error\n",
        "    ax = fig.add_subplot(3, 3, 9)\n",
        "    psihat = jnp.fft.fftshift(jnp.fft.fft2(U - U_p))\n",
        "    tke = jnp.real(.5 * k2 * psihat * jnp.conj(psihat))\n",
        "    kmod = jnp.sqrt(k2)\n",
        "    k = jnp.arange(1, psihat.shape[0] // 2 + 1, 1, dtype=jnp.float64) # nyquist limit for this grid\n",
        "    E = jnp.zeros_like(k)\n",
        "    res = 200 # resolution\n",
        "    dk = (jnp.max(k) - jnp.min(k)) / res\n",
        "\n",
        "        #  binning energies with wavenumber modulus in threshold\n",
        "    for i in range(len(k)):\n",
        "        E = E.at[i].add(jnp.sum(tke[(kmod < k[i] + dk) & (kmod >= k[i] - dk)]))\n",
        "    sum_E = jnp.sum(E)\n",
        "        # angle averaged Turbulent Kinetic Energy spectrum\n",
        "    ax.loglog(k, E, '-b', label = \"Error E(k)\")\n",
        "    ax.set_xlabel(\"k\")\n",
        "    ax.set_ylabel(\"E(k)\")\n",
        "    ax.legend()\n",
        "\n",
        "\n",
        "    # Loss\n",
        "    if loss is not None:\n",
        "        ax = fig.add_subplot(3, 3, 6)\n",
        "        ax.set_ylabel(\"Loss\", fontsize = axis_fontsize, rotation = 90)\n",
        "        ax.set_yscale('log')\n",
        "        n = 0\n",
        "        # Plot loss, labeled by optimization method\n",
        "        for i, loss_i in enumerate(loss):\n",
        "            n_iter = len(loss_i)\n",
        "            ax.plot(jnp.arange(n, n + n_iter), loss_i, '-', linewidth = 2, label = f\"Stage {i} Loss\")\n",
        "            n += n_iter\n",
        "        ax.legend()\n",
        "\n",
        "    # plt.tight_layout()\n",
        "    fig.suptitle(title)\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(filename)\n",
        "    plt.show()\n",
        "    plt.close('all')\n",
        "\n",
        "# U_p_stages.append(U_p)\n",
        "# eps_stages.append(eps * (-1) ** stage)\n",
        "print(eps_stages)\n",
        "# sum_start = eps_stages[0] * jnp.array(U_p_stages[0])\n",
        "# plot_results(U_0, sum_start, loss = None, stage = stage, filename = f'{description}', title = f\"Stage {stage} intermediate\")\n",
        "\n",
        "# for i in range(1, len(U_p_stages)):\n",
        "#     # plot_results(eps_stages[i] * jnp.array(U_p_stages[i]), eps_stages[i] * jnp.array(U_p_stages[i]), loss = None, stage = stage, filename = f'{description}', title = f\"Stage {stage} intermediate\")\n",
        "#     sum_start += eps_stages[i] * 1 / eps_stages[0] * eps_stages[1] * jnp.array(U_p_stages[i])\n",
        "#     plot_results(U_0, sum_start, loss = None, stage = stage, filename = f'{description}', title = f\"Stage {stage} intermediate\")\n",
        "\n",
        "loss_stages_eps = []\n",
        "for i, loss in enumerate(loss_stages):\n",
        "    print(f\"{i=}, {loss=}\")\n",
        "    loss_stages_eps.append(eps_stages[i] * jnp.array(loss))\n",
        "\n",
        "U_p_total = jnp.sum(jnp.array(U_p_stages), axis = 0)\n",
        "plot_results(U_0, U_p_total, loss = loss_stages_eps, stage = stage, filename = f'{description}_total_results.png', title = f\"Stage {stage} Total Results\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tyfVZzaee6TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "#import jax.numpy as np\n",
        "import numpy as np\n",
        "\n",
        "dpi = 300\n",
        "fig = plt.figure(dpi = dpi)\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "stages = []\n",
        "for i in range(4):\n",
        "    stages.append(scipy.io.loadmat(f\"reg2d_test2_p10_iters150000_stage{i}_fourinitTrue_act1_10000_results copy.mat\"))\n",
        "stages_long = scipy.io.loadmat(\"reg2d_test2_p10_iters600000_stage0_fourinitTrue_act1_10000_results copy.mat\")\n",
        "X = stages_long['X']\n",
        "Y = stages_long['Y']\n",
        "U = stages_long['U']\n",
        "N_x, N_y = X.shape\n",
        "lb = [-1, -1]\n",
        "ub = [1, 1]\n",
        "limit = np.array([lb, ub])\n",
        "print(f\"{N_x=}, {N_y=}\")\n",
        "\n",
        "# Frequencies of actual solution\n",
        "timestep = np.array([N_x, N_y]) / (limit[1] - limit[0])\n",
        "freq_x = np.fft.fftshift(np.fft.fftfreq(n = N_x, d = 1 / timestep[0])) # frequency in multiples of 1/pi cycles/second\n",
        "freq_y = np.fft.fftshift(np.fft.fftfreq(n = N_y, d = 1 / timestep[1]))\n",
        "norm = 'forward'\n",
        "# Energy spectrum of actual solution\n",
        "KX, KY = np.meshgrid(freq_x, freq_y)\n",
        "k2 = KX ** 2 + KY ** 2 # wave number squared\n",
        "\n",
        "# for target, label, color in [(U, \"Target E(k)\", \"k\"), (stages[0]['U_p'], \"Stage 0, 150000 iterations\", \"k\"), (stages[0]['U_p'] + stages[1]['U_p'], \"Stage 1, 150000 iterations\", \"b\"), (stages[0]['U_p'] + stages[1]['U_p'] + stages[2]['U_p'], \"Stage 2, 150000 iterations\", \"g\"), (stages_long['U_p'], \"Stage 0, 600000 iterations\", \"r\")]:\n",
        "for target, label, color in [(U, \"Target E(k)\", \"k\"), (stages[0]['U_p'] + stages[1]['U_p'] + stages[2]['U_p'] + stages[3]['U_p'], \"Stage 3, 150000 iterations\", \"g\"), (stages_long['U_p'], \"Stage 0, 600000 iterations\", \"r\")]:\n",
        "    psihat = np.fft.fftshift(np.fft.fft2(target))\n",
        "    tke = np.real(.5 * k2 * psihat * np.conj(psihat))\n",
        "    kmod = np.sqrt(k2)\n",
        "    k = np.arange(1, psihat.shape[0] // 2 + 1, 1, dtype=np.float64) # nyquist limit for this grid\n",
        "    E = np.zeros_like(k)\n",
        "    res = 200 # resolution\n",
        "    dk = (np.max(k) - np.min(k)) / res\n",
        "\n",
        "    #  binning energies with wavenumber modulus in threshold\n",
        "    for i in range(len(k)):\n",
        "        E[i] += np.sum(tke[(kmod < k[i] + dk) & (kmod >= k[i] - dk)])\n",
        "    sum_E = np.sum(E)\n",
        "        # angle averaged Turbulent Kinetic Energy spectrum\n",
        "    if label == 'Target E(k)':\n",
        "        ax.loglog(k, E, f'-{color}', label = label, alpha = 0.2, linewidth = 5)\n",
        "    else:\n",
        "        ax.loglog(k, E, f'-{color}', label = label)\n",
        "ax.set_xlabel(\"Wavenumber k\")\n",
        "ax.set_ylabel(\"E(k)\")\n",
        "ax.legend()\n",
        "ax.set_title(\"2D Turbulence Energy Spectrum\")\n",
        "plt.savefig(\"reg2d_test2_p10_iters150000_stage0_fourinitTrue_act1_10000_energy_spectrum.png\")\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "axis_fontsize = 12\n",
        "stage0loss = stages[0]['loss'][0]\n",
        "stage1loss = stages[1]['loss'][0]\n",
        "stage2loss = stages[2]['loss'][0]\n",
        "stage3loss = stages[3]['loss'][0]\n",
        "stage0loss_long = stages_long['loss'][0]\n",
        "\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.set_ylabel(\"Loss\", fontsize = axis_fontsize, rotation = 90)\n",
        "ax.set_xlabel(\"Iterations\")\n",
        "ax.set_title(\"Loss Convergence\")\n",
        "ax.set_yscale('log')\n",
        "\n",
        "\n",
        "ax.plot(np.arange(0, stage0loss_long.shape[0]), stage0loss_long, '-r', linewidth = 1, label = f\"Stage 0, 600000 iterations\")\n",
        "ax.plot(np.arange(0, stage0loss.shape[0]), stage0loss, '--k', linewidth = 1, label = f\"Stage 0, 150000 iterations\")\n",
        "ax.plot(np.arange(stage0loss.shape[0], stage0loss.shape[0] + stage1loss.shape[0]), stage1loss, '-b', linewidth = 1, label = f\"Stage 1, 150000 iterations\")\n",
        "ax.plot(np.arange(stage0loss.shape[0] + stage1loss.shape[0], stage0loss.shape[0] + stage1loss.shape[0] + stage2loss.shape[0]), stage2loss, '-g', linewidth = 1, label = f\"Stage 2, 150000 iterations\")\n",
        "ax.plot(np.arange(stage0loss.shape[0] + stage1loss.shape[0] + stage2loss.shape[0], stage0loss.shape[0] + stage1loss.shape[0] + stage2loss.shape[0] + stage3loss.shape[0]), stage3loss, color = 'orange', linewidth = 1, label = f\"Stage 3, 150000 iterations\")\n",
        "\n",
        "ax.legend()\n",
        "plt.savefig(\"reg2d_test2_p10_iters150000_stage0_fourinitTrue_act1_10000_loss.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qb8-44x1T_95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1701\n",
        "key = jax.random.key(seed)\n",
        "key1, key2, key3 = jax.random.split(key, num = 3)\n",
        "# H.shape=(900, 120), layer[0].shape=(120, 30), layer[1].shape=(30,)\n",
        "\n",
        "\n",
        "# shape of layer[0] is [10 x 10]\n",
        "# shape of H is []\n",
        "H = jax.random.normal(key = key1, shape = (900, 1200))\n",
        "layer = []\n",
        "layer.append(jax.random.normal(key = key2, shape = (1200, 30)))\n",
        "layer.append(jax.random.normal(key = key3, shape = (30,)))\n",
        "\n",
        "# result = jnp.tanh(jnp.dot(H, layer[0]) + layer[1])\n",
        "\n",
        "max_width = 123\n",
        "result0 = jnp.dot(H[:, :max_width], layer[0][:max_width])\n",
        "print(f\"{result0.shape=}\")\n",
        "for i in range(1, int(jnp.ceil(layer[0].shape[0] / max_width))):\n",
        "    # print(H[i * max_width : (i + 1) * max_width].shape)\n",
        "    # print(result0)\n",
        "    # print(jnp.dot(H[i * max_width : (i + 1) * max_width], layer[0]))\n",
        "    result0 = result0 + jnp.dot(H[:, i * max_width : (i + 1) * max_width], layer[0][i * max_width : (i + 1) * max_width])\n",
        "# print(layer[0])\n",
        "print(f\"{result0.shape=}\")\n",
        "result = jnp.dot(H, layer[0])\n",
        "print(f\"{jnp.all(jnp.abs(result0 - result) <= 0.000000000001)=}\")"
      ],
      "metadata": {
        "id": "ofjrTa4eHEpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "L = 2 * np.pi\n",
        "N = 512\n",
        "kx = np.fft.fftfreq(N, d = L / (N * 2 * np.pi))\n",
        "print(f\"{kx=}\")\n",
        "kx_bad = np.fft.fftfreq(N, d = 2 / (N))\n",
        "print(f\"{kx_bad=}\")"
      ],
      "metadata": {
        "id": "kpVmRlYEvews"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18AXIEMht3f9jWVcLWepQN96strHL2D69",
      "authorship_tag": "ABX9TyMvdZIwV3bjGTLnHebxP1nW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}